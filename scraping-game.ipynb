{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import _pickle as cPickle\n",
    "from os.path import exists\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetMetaGameInfo(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    scorebox = soup.find(\"div\", {\"class\": \"scorebox\"})\n",
    "    t1, t2, score_box_meta = (list(scorebox.children)[i] for i in [1,3,5])\n",
    "    for t in [t1, t2]:\n",
    "        t.name = t.find(\"strong\").text.strip(\" \").strip(\"\\n\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "        t.score = int(t.find(\"div\", {\"class\": \"score\"}).text)\n",
    "        t.pre_win, t.pre_loss = (int(i) for i in list(t.children)[4].text.split('-'))\n",
    "    if t1.score > t2.score:\n",
    "        t1.pre_win -= 1\n",
    "        t2.pre_loss -= 1\n",
    "    else:\n",
    "        t2.pre_win -= 1\n",
    "        t1.pre_loss -= 1\n",
    "    scorebox = soup.find(\"div\", {\"class\": \"scorebox\"})\n",
    "    t1, t2, score_box_meta = (list(scorebox.children)[i] for i in [1,3,5])\n",
    "    rows = [i.text for i in list(score_box_meta.children) if i != '\\n']\n",
    "    date = rows[0]\n",
    "    start_time = [row for row in rows if \"Start Time:\" in row][0]\n",
    "    att = [row for row in rows if \"Attendance:\" in row]\n",
    "    have_att = len(att) != 0\n",
    "    att = -1 if have_att == False else att[0]\n",
    "    venue = [row for row in rows if \"Venue:\" in row][0]\n",
    "    duration = [row for row in rows if \"Game Duration:\" in row][0]\n",
    "    at_night_on_grass = [row for row in rows if \"on \" in row][0]\n",
    "    # date, start_time, att, venue, duration, at_night_on_grass = list(list(score_box_meta.children)[i].text for i in [1, 2, 3, 4, 5, 6] )\n",
    "    at_night = None\n",
    "    on_grass = None\n",
    "    info_dict = dict()\n",
    "    if have_att:\n",
    "        date = datetime.strptime(date, \"%A, %B %d, %Y\")\n",
    "        start_time = datetime.strptime(\"\".join(start_time.split(\" \")[2:4]).replace(\".\", \"\"), \"%I:%M%p\")\n",
    "        start_time = date + timedelta(hours=start_time.hour, minutes=start_time.minute)\n",
    "        duration = datetime.strptime(duration[15:], \"%H:%M\")\n",
    "        duration = timedelta(hours=duration.hour, minutes=duration.minute)\n",
    "        at_night, on_grass = at_night_on_grass.split(\", \")\n",
    "        at_night = 'Night Game' == at_night\n",
    "        on_grass = 'on grass' == on_grass\n",
    "        att = int(att.split(\": \")[1].replace(\",\", \"\"))\n",
    "        venue = venue.split(\": \")[1]\n",
    "        infos = list(soup.find('h2', text=\"Other Info\").parent.parent.find(\"div\", {\"class\" : \"section_content\"}).children)\n",
    "        infos = [i for i in infos if '\\n' != i]\n",
    "        for info in infos:\n",
    "            k,v = info.text.split(\":\", 1)\n",
    "            info_dict[k] = v\n",
    "    gameInfo = {\n",
    "        \"have_att\": have_att,\n",
    "        \"start_time\": start_time, \"duration\": duration,\n",
    "        \"venue\": venue, \"at_night\": at_night, \"on_grass\": on_grass,\n",
    "        'Start Time Weather': \"\" if 'Start Time Weather' not in info_dict else  info_dict['Start Time Weather'],\n",
    "        'Umpires': \"\" if \"Umpires\" not in info_dict else info_dict['Umpires'],\n",
    "        \"att\": att\n",
    "    }\n",
    "    return t1, t2, gameInfo\n",
    "\n",
    "# soup = BeautifulSoup(, \"html.parser\")\n",
    "def GetTable(html, table_id):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    tbody = soup.find(\"div\", {\"id\": table_id}).find(\"tbody\")\n",
    "    table = []\n",
    "    for tr in tbody.findAll(\"tr\"):\n",
    "        row = []\n",
    "        name = tr.find(\"th\").text\n",
    "        row.append(name)\n",
    "        for td in tr.findAll(\"td\"):\n",
    "            row.append(td.text)\n",
    "        if not all([i == \"\" for i in row]):\n",
    "            table.append(row)\n",
    "    return pd.DataFrame(table, columns=[\n",
    "        'Batting',\n",
    "        'AB',\n",
    "        'R',\n",
    "        'H',\n",
    "        'RBI',\n",
    "        'BB',\n",
    "        'SO',\n",
    "        'PA',\n",
    "        'BA',\n",
    "        'OBP',\n",
    "        'SLG',\n",
    "        'OPS',\n",
    "        'Pit',\n",
    "        'Str',\n",
    "        'WPA',\n",
    "        'aLI',\n",
    "        'WPA+',\n",
    "        'WPA-',\n",
    "        'cWPA',\n",
    "        'acLI',\n",
    "        'RE24',\n",
    "        'PO',\n",
    "        'A',\n",
    "        'Details'\n",
    "    ])\n",
    "    \n",
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.headless = False\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "    ### This blocks images and javascript requests\n",
    "    chrome_prefs = {\n",
    "        \"profile.default_content_setting_values\": {\n",
    "            \"images\": 2,\n",
    "        }\n",
    "    }\n",
    "    chrome_options.experimental_options[\"prefs\"] = chrome_prefs\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager(\n",
    "    ).install()), options=options)#, chrome_options=chrome_options)\n",
    "    driver.set_page_load_timeout(4)\n",
    "    return driver\n",
    "\n",
    "def scratch_meta_page(url):\n",
    "    driver = setup_driver()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "        except TimeoutException:\n",
    "            print(\"load page timeout\")\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 1).until(EC.presence_of_element_located(\n",
    "                    (By.CLASS_NAME, \"game\")))\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "        break\n",
    "    print(\"get meta page data\")\n",
    "    return driver.page_source\n",
    "\n",
    "\n",
    "def scratch_single_page(url):\n",
    "    print(f\"Scratching {url}\")\n",
    "    driver=setup_driver()\n",
    "\n",
    "    # load page for 4 sec\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except TimeoutException:\n",
    "        print(\"load page timeout\")\n",
    "\n",
    "    team1, team2, metaGameInfo = GetMetaGameInfo(driver.page_source)\n",
    "    df1=GetTable(driver.page_source, f\"all_{team1.name}batting\")\n",
    "    df2=GetTable(driver.page_source, f\"all_{team2.name}batting\")\n",
    "    print(\"get page data success\")\n",
    "    \n",
    "    team1={\n",
    "        \"name\": team1.name,\n",
    "        \"pre_win\": team1.pre_win,\n",
    "        \"pre_loss\": team1.pre_loss,\n",
    "        \"player_df\": df1\n",
    "    }\n",
    "    team2={\n",
    "        \"name\": team2.name,\n",
    "        \"pre_win\": team2.pre_win,\n",
    "        \"pre_loss\": team2.pre_loss,\n",
    "        \"player_df\": df2\n",
    "    }\n",
    "\n",
    "    gameInfo={\n",
    "        \"meta_game_info\": metaGameInfo,\n",
    "        \"team1\": team1,\n",
    "        \"team2\": team2\n",
    "    }\n",
    "\n",
    "    return gameInfo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_by_years(years):\n",
    "    for year in years:\n",
    "        print(f\"get games from year: {year}\")\n",
    "        # load previous scratched games data\n",
    "        if exists(f\"gamesData{year}.pickle\"):\n",
    "            with open(f\"gamesData{year}.pickle\", \"rb\") as output_file:\n",
    "                data = cPickle.load(output_file)\n",
    "        else:\n",
    "            data = dict()\n",
    "        \n",
    "        # get all year's game from schedule page\n",
    "        html = scratch_meta_page(f\"https://www.baseball-reference.com/leagues/majors/{year}-schedule.shtml\")\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        games = soup.findAll(\"p\", {\"class\": \"game\"})\n",
    "        print(f\"have {len(games)} to scrap\")\n",
    "        # scratch the rest\n",
    "        for game in games:\n",
    "            for i in range(5):# max retry 5 time\n",
    "                game_url = \"https://www.baseball-reference.com\" + game.find(\"em\").find(\"a\")['href']\n",
    "                if game_url not in data:\n",
    "                    #scratch game\n",
    "                    try:\n",
    "                        gameInfo = scratch_single_page(game_url)\n",
    "                        # save to data\n",
    "                        data[game_url] = gameInfo\n",
    "                        with open(f\"gamesData{year}.pickle\", \"wb\") as output_file:\n",
    "                            cPickle.dump(data, output_file)\n",
    "                        break\n",
    "                    except KeyboardInterrupt:\n",
    "                        raise\n",
    "                    except AttributeError:\n",
    "                        print(\"something wrong, retry scrap this page\")\n",
    "                        continue\n",
    "                else:\n",
    "                    break\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = scratch_single_page(\"https://www.baseball-reference.com/boxes/CHA/CHA201704040.shtml\")\n",
    "# soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get games from year: 2017\n",
      "load page timeout\n",
      "get meta page data\n",
      "have 2468 to scrap\n",
      "Scratching https://www.baseball-reference.com/boxes/SLN/SLN201706131.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/MIN/MIN201706171.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/SLN/SLN201706260.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/DET/DET201707011.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/KCA/KCA201707011.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/BOS/BOS201707161.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/CLE/CLE201707240.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/WAS/WAS201707301.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/HOU/HOU201707310.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/NYA/NYA201707310.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/HOU/HOU201708010.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/COL/COL201708020.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/KCA/KCA201708061.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/CHA/CHA201708080.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/CIN/CIN201708090.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/SLN/SLN201708120.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/NYA/NYA201708130.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/OAK/OAK201708130.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/SLN/SLN201708130.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/TOR/TOR201708130.shtml\n",
      "load page timeout\n",
      "Day Game, on turf\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/WAS/WAS201708131.shtml\n",
      "load page timeout\n",
      "Day Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/BOS/BOS201708140.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/CHN/CHN201708160.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/NYN/NYN201708160.shtml\n",
      "load page timeout\n",
      "Night Game, on grass\n",
      "get page data success\n",
      "Scratching https://www.baseball-reference.com/boxes/SEA/SEA201708160.shtml\n",
      "load page timeout\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'children'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m y2 \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m2019\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m2018\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m y3 \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m2017\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m2016\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m2015\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m scrap_by_years(y3)\n",
      "Cell \u001b[0;32mIn [73], line 23\u001b[0m, in \u001b[0;36mscrap_by_years\u001b[0;34m(years)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m game_url \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data:\n\u001b[1;32m     21\u001b[0m     \u001b[39m#scratch game\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m         gameInfo \u001b[39m=\u001b[39m scratch_single_page(game_url)\n\u001b[1;32m     24\u001b[0m         \u001b[39m# save to data\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         data[game_url] \u001b[39m=\u001b[39m gameInfo\n",
      "Cell \u001b[0;32mIn [72], line 145\u001b[0m, in \u001b[0;36mscratch_single_page\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mexcept\u001b[39;00m TimeoutException:\n\u001b[1;32m    143\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mload page timeout\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m team1, team2, metaGameInfo \u001b[39m=\u001b[39m GetMetaGameInfo(driver\u001b[39m.\u001b[39;49mpage_source)\n\u001b[1;32m    146\u001b[0m df1\u001b[39m=\u001b[39mGetTable(driver\u001b[39m.\u001b[39mpage_source, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall_\u001b[39m\u001b[39m{\u001b[39;00mteam1\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39mbatting\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m df2\u001b[39m=\u001b[39mGetTable(driver\u001b[39m.\u001b[39mpage_source, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall_\u001b[39m\u001b[39m{\u001b[39;00mteam2\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39mbatting\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [72], line 4\u001b[0m, in \u001b[0;36mGetMetaGameInfo\u001b[0;34m(html)\u001b[0m\n\u001b[1;32m      2\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(html, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m scorebox \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mscorebox\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m----> 4\u001b[0m t1, t2, score_box_meta \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(scorebox\u001b[39m.\u001b[39mchildren)[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m5\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m [t1, t2]:\n\u001b[1;32m      6\u001b[0m     t\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mstrong\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstrip(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [72], line 4\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(html, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m scorebox \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mscorebox\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m----> 4\u001b[0m t1, t2, score_box_meta \u001b[39m=\u001b[39m (\u001b[39mlist\u001b[39m(scorebox\u001b[39m.\u001b[39;49mchildren)[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m5\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m [t1, t2]:\n\u001b[1;32m      6\u001b[0m     t\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mstrong\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mstrip(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'children'"
     ]
    }
   ],
   "source": [
    "# year to scrap\n",
    "# years = [\"2022\", \"2021\", \"2019\", \"2018\", \"2017\", \"2016\", \"2015\"]\n",
    "y1 = [\"2022\", \"2021\"]\n",
    "y2 = [\"2019\", \"2018\"]\n",
    "y3 = [\"2017\", \"2016\", \"2015\"]\n",
    "\n",
    "scrap_by_years(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2407"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"gamesData{2017}.pickle\", \"rb\") as output_file:\n",
    "            data = cPickle.load(output_file)\n",
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43df744c98c246816ca7c9cbc62e6caeb27475d47e1cd721e7fc30f17cf8524c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
