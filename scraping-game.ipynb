{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import _pickle as cPickle\n",
    "import threading\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetMetaGameInfo(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    scorebox = soup.find(\"div\", {\"class\": \"scorebox\"})\n",
    "    t1, t2, score_box_meta = (list(scorebox.children)[i] for i in [1,3,5])\n",
    "    for t in [t1, t2]:\n",
    "        t.name = t.find(\"strong\").text.strip(\" \").strip(\"\\n\").replace(\" \", \"\").replace(\".\", \"\")\n",
    "        t.score = int(t.find(\"div\", {\"class\": \"score\"}).text)\n",
    "        t.pre_win, t.pre_loss = (int(i) for i in list(t.children)[4].text.split('-'))\n",
    "    if t1.score > t2.score:\n",
    "        t1.pre_win -= 1\n",
    "        t2.pre_loss -= 1\n",
    "    else:\n",
    "        t2.pre_win -= 1\n",
    "        t1.pre_loss -= 1\n",
    "    date, start_time, att, venue, duration, at_night_on_grass = list(list(score_box_meta.children)[i].text for i in [1, 2, 3, 4, 5, 6] )\n",
    "    have_att = \"Attendance\" in att\n",
    "    at_night = None\n",
    "    on_grass = None\n",
    "    if have_att:\n",
    "        date = datetime.strptime(date, \"%A, %B %d, %Y\")\n",
    "        start_time = datetime.strptime(\"\".join(start_time.split(\" \")[2:4]).replace(\".\", \"\"), \"%I:%M%p\")\n",
    "        start_time = date + timedelta(hours=start_time.hour, minutes=start_time.minute)\n",
    "        duration = datetime.strptime(duration[15:], \"%H:%M\")\n",
    "        duration = timedelta(hours=duration.hour, minutes=duration.minute)\n",
    "        at_night, on_grass = at_night_on_grass.split(\", \")\n",
    "        at_night = 'Night Game' == at_night\n",
    "        on_grass = 'on grass' == on_grass\n",
    "        att = int(att.split(\": \")[1].replace(\",\", \"\"))\n",
    "        venue = venue.split(\": \")[1]    \n",
    "    gameInfo = {\n",
    "        \"have_att\": have_att,\n",
    "        \"start_time\": start_time, \"duration\": duration,\n",
    "        \"venue\": venue, \"at_night\": at_night, \"on_grass\": on_grass,\n",
    "        \"att\": att\n",
    "    }\n",
    "    return t1, t2, gameInfo\n",
    "\n",
    "# soup = BeautifulSoup(, \"html.parser\")\n",
    "def GetTable(html, table_id):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    tbody = soup.find(\"div\", {\"id\": table_id}).find(\"tbody\")\n",
    "    table = []\n",
    "    for tr in tbody.findAll(\"tr\"):\n",
    "        row = []\n",
    "        name = tr.find(\"th\").text\n",
    "        row.append(name)\n",
    "        for td in tr.findAll(\"td\"):\n",
    "            row.append(td.text)\n",
    "        if not all([i == \"\" for i in row]):\n",
    "            table.append(row)\n",
    "    return pd.DataFrame(table, columns=[\n",
    "        'Batting',\n",
    "        'AB',\n",
    "        'R',\n",
    "        'H',\n",
    "        'RBI',\n",
    "        'BB',\n",
    "        'SO',\n",
    "        'PA',\n",
    "        'BA',\n",
    "        'OBP',\n",
    "        'SLG',\n",
    "        'OPS',\n",
    "        'Pit',\n",
    "        'Str',\n",
    "        'WPA',\n",
    "        'aLI',\n",
    "        'WPA+',\n",
    "        'WPA-',\n",
    "        'cWPA',\n",
    "        'acLI',\n",
    "        'RE24',\n",
    "        'PO',\n",
    "        'A',\n",
    "        'Details'\n",
    "    ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver():\n",
    "    options = Options()\n",
    "    options.headless = False\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager(\n",
    "    ).install()), options=options)\n",
    "    driver.set_page_load_timeout(5)\n",
    "    return driver\n",
    "\n",
    "def scratch_meta_page():\n",
    "    url = \"https://www.baseball-reference.com/leagues/majors/2021-schedule.shtml\"\n",
    "    driver = setup_driver()\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "        except TimeoutException:\n",
    "            print(\"load page timeout\")\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 1).until(EC.presence_of_element_located(\n",
    "                    (By.CLASS_NAME, \"game\")))\n",
    "        except TimeoutException:\n",
    "            continue\n",
    "        break\n",
    "    print(\"get meta data\")\n",
    "    return driver.page_source\n",
    "\n",
    "\n",
    "def scratch_single_page(url):\n",
    "    print(f\"Scratch {url}\")\n",
    "    driver=setup_driver()\n",
    "\n",
    "    # load page for 4 sec\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except TimeoutException:\n",
    "        print(\"load page timeout\")\n",
    "\n",
    "    team1, team2, metaGameInfo = GetMetaGameInfo(driver.page_source)\n",
    "    df1=GetTable(driver.page_source, f\"all_{team1.name}batting\")\n",
    "    df2=GetTable(driver.page_source, f\"all_{team2.name}batting\")\n",
    "    print(\"get page data success\")\n",
    "    \n",
    "    team1={\n",
    "        \"name\": team1.name,\n",
    "        \"pre_win\": team1.pre_win,\n",
    "        \"pre_loss\": team1.pre_loss,\n",
    "        \"player_df\": df1\n",
    "    }\n",
    "    team2={\n",
    "        \"name\": team2.name,\n",
    "        \"pre_win\": team2.pre_win,\n",
    "        \"pre_loss\": team2.pre_loss,\n",
    "        \"player_df\": df2\n",
    "    }\n",
    "\n",
    "    gameInfo={\n",
    "        \"meta_game_info\": metaGameInfo,\n",
    "        \"team1\": team1,\n",
    "        \"team2\": team2\n",
    "    }\n",
    "\n",
    "    return gameInfo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the index page get all game url\n",
    "html = scratch_meta_page()\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "games = soup.findAll(\"p\", {\"class\": \"game\"})\n",
    "random.shuffle(games)\n",
    "\n",
    "# scratch the rest\n",
    "for game in games:\n",
    "    # load previous scratched games data\n",
    "    with open(\"gamesData.pickle\", \"rb\") as output_file:\n",
    "        data = cPickle.load(output_file)\n",
    "    \n",
    "    game_url = \"https://www.baseball-reference.com\" + g.find(\"em\").find(\"a\")['href']\n",
    "    if game_url not in data:\n",
    "        #scratch game\n",
    "        try:\n",
    "            gameInfo = scratch_single_page(game_url)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        # save to data\n",
    "        data[game_url] = gameInfo\n",
    "        with open(\"gamesData.pickle\", \"wb\") as output_file:\n",
    "            cPickle.dump(data, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gamesData.pickle\", \"rb\") as output_file:\n",
    "    data = cPickle.load(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43df744c98c246816ca7c9cbc62e6caeb27475d47e1cd721e7fc30f17cf8524c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
