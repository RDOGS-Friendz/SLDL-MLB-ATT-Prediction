{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import _pickle as cPickle\n",
    "from os.path import exists\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_driver(time_out=4):\n",
    "    options = Options()\n",
    "    options.headless = False\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "    ### This blocks images and javascript requests\n",
    "    chrome_prefs = {\n",
    "        \"profile.default_content_setting_values\": {\n",
    "            \"images\": 2,\n",
    "        }\n",
    "    }\n",
    "    options.add_argument(\"--window-size=100,100\")\n",
    "    chrome_options.experimental_options[\"prefs\"] = chrome_prefs\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager(\n",
    "    ).install()), options=options, chrome_options=chrome_options)\n",
    "    driver.set_page_load_timeout(time_out)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get teams abbreviations\n",
    "with open('./TeamAbbrDict.json', 'r') as f:\n",
    "    abbreviations = json.loads(f.read())\n",
    "\n",
    "\n",
    "# init all year dict\n",
    "years = [2017, 2018, 2019, 2020, 2021, 2022]\n",
    "df_by_year_abbr_dict = dict()\n",
    "for year in years:\n",
    "    df_by_year_abbr_dict[year] = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    # get urls to scrap\n",
    "    urls = [f\"https://www.baseball-reference.com/teams/{abbr}/{year}.shtml\" for abbr in abbreviations.values()]\n",
    "\n",
    "    for i,( abbr, url) in enumerate(zip(abbreviations.values(), urls)):\n",
    "        # skip already scraped\n",
    "        if abbr in df_by_year_abbr_dict[year]:\n",
    "            continue\n",
    "        \n",
    "        driver = setup_driver(time_out=3)\n",
    "        try:\n",
    "            print(f\"[{i+1}/30] scraping {abbr} data..\")\n",
    "            driver.get(url)\n",
    "        except TimeoutException:\n",
    "            print(\"load page timeout\")\n",
    "            pass\n",
    "\n",
    "        # find the table\n",
    "        body = driver.find_elements(By.XPATH, \"//div[@id='div_appearances']//tbody//tr\")\n",
    "        # get each row\n",
    "        data = []\n",
    "        for row in (body):\n",
    "            player_name = row.find_element(By.TAG_NAME, \"th\").text\n",
    "            player_salary = row.find_element(By.CSS_SELECTOR, \"td[data-stat='Salary'\").text\n",
    "            player_allstar_appearance = row.find_element(By.CSS_SELECTOR, \"td[data-stat='allstar_appearance'\").text\n",
    "            data.append([player_name, player_salary, player_allstar_appearance])\n",
    "        # write to df\n",
    "        data = np.array(data)\n",
    "        df = pd.DataFrame(data=data, columns=['Name', 'Salary', 'AllStartAppearance'])\n",
    "        df = df[(df['Salary'] != '') | (df['AllStartAppearance'] != '')]\n",
    "        df_by_year_abbr_dict[year][abbr] = df\n",
    "        print(f\"scrap success {abbr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df\n",
    "with open(f\"player-salaries.pickle\", \"wb\") as output_file:\n",
    "    cPickle.dump(df_by_year_abbr_dict, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df\n",
    "with open(f\"player-salaries.pickle\", \"rb\") as in_file:\n",
    "    data = cPickle.load(in_file)\n",
    "\n",
    "# access data by year by team abbreviation, abbreviation can be found in TeamAbbrDict.json\n",
    "data[2022]['BOS']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43df744c98c246816ca7c9cbc62e6caeb27475d47e1cd721e7fc30f17cf8524c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
